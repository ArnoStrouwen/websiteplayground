[{"content":"Statistical Consultant ","date":null,"permalink":"/websiteplayground/","section":"","summary":"Statistical Consultant ","title":""},{"content":"Blog Archive ","date":null,"permalink":"/websiteplayground/posts/","section":"","summary":"Blog Archive ","title":""},{"content":"Under Construction Z-test\n","date":null,"permalink":"/websiteplayground/ssi/","section":"","summary":"Under Construction Z-test","title":""},{"content":"Under Construction for now\n","date":"1 January 2024","permalink":"/websiteplayground/ssi/z-test/","section":"","summary":"Under Construction for now","title":"Exact Small Sample Statistical Inference for Z-test"},{"content":" Most experimental design focusses on parameter precision, where the model structure is assumed known and fixed. But arguably finding the correct model structure is the part of the modelling process that takes the most effort. In this blog we will look at automating this process using symbolic regression, and to do this with gathering too much data.\nThe Julia packages that we will use:\nusing SymbolicRegression using Symbolics, SymbolicUtils using Distributions using Optimization, OptimizationBBO using Plots using Random; Random.seed!(12345) We will try to discover the equation: $$y(x) = \\exp(-x)\\sin(2\\pi x) + \\cos(\\frac{\\pi}{2}x), \\qquad 0 \\leq x \\leq 10,$$ automatically from data. Translated into Julia code:\ny(x) = exp(-x)*sin(2π*x) + cos(π/2*x) y(0.0) 1.0 As a baseline design let us gather 10 points randomly from the design space.\nn_obs = 10 design_region = Uniform(0.0,10.0) X = rand(design_region,n_obs) Y = y.(X) plot(0.0:0.1:10.0,y.(0.0:0.1:10.0),label=\u0026#34;true model\u0026#34;,lw=5,ls=:dash); scatter!(X,Y,ms=5,label=\u0026#34;data\u0026#34;); plot!(xlabel=\u0026#34;x\u0026#34;,ylabel=\u0026#34;y\u0026#34;, ylims=(-1.2,1.8)); plot!(tickfontsize=12, guidefontsize=14, legendfontsize=8, grid=false, dpi=600) Now let us perform symbolic regression on this dataset. We will look for 10 model structures that fit the data.\noptions = SymbolicRegression.Options( unary_operators = (exp, sin, cos), binary_operators=(+, *, /, -), seed=123, deterministic=true ) hall_of_fame = EquationSearch(X\u0026#39;, Y, options=options, niterations=100, runtests=false, parallelism=:serial) n_best_max = 10 #incase \u0026lt; 10 model structures were returned n_best = min(length(hall_of_fame.members),n_best_max) best_models = sort(hall_of_fame.members,by=member-\u0026gt;member.loss)[1:n_best] Started! 10-element Vector{SymbolicRegression.PopMemberModule.PopMember{Float64}}: SymbolicRegression.PopMemberModule.PopMember{Float64}((cos(x1 * -1.5707472 736173678) - sin(sin(exp(x1) / cos(sin((x1 * 0.11489592239489567) + 0.02924 150694094207))) / exp(x1))), 0.06403884841950626, 1.0187179197773552e-5, 24 01441, 5807529618927081144, 5795836981119531379) SymbolicRegression.PopMemberModule.PopMember{Float64}((cos(x1 * -1.5707472 736173678) - (sin(exp(x1) / cos(sin((x1 * 0.11489592239489567) + 0.02924150 694094207))) / exp(x1))), 0.06083908652153372, 1.0249160815942009e-5, 20897 28, 4358865566510575018, 1198926568467179219) SymbolicRegression.PopMemberModule.PopMember{Float64}((cos(x1 / 0.63660506 56890262) - sin(sin(exp(x1) / cos(sin(0.11489592239489567) * x1)) / exp(x1) )), 0.057681573488650405, 2.1388759091569173e-5, 1738646, 35215362873834417 13, 1106443898740131553) SymbolicRegression.PopMemberModule.PopMember{Float64}((cos(x1 / 0.63660506 56890262) - sin(sin(exp(x1) / cos(0.11489592239489567 * x1)) / exp(x1))), 0 .054481940153208334, 2.148542646434505e-5, 1683449, 1106443898740131553, 44 63609806790343470) SymbolicRegression.PopMemberModule.PopMember{Float64}((cos(x1 / 0.63660506 56890262) - (sin(exp(x1) / cos(0.11489592239489567 * x1)) / exp(x1))), 0.05 1288010332056364, 2.3076573687286177e-5, 1458762, 4463609806790343470, 2723 675212815722575) SymbolicRegression.PopMemberModule.PopMember{Float64}((cos(x1 / 0.63660506 56890262) - (sin(exp(x1) * 1.0363388900284802) / (exp(x1) - 0.1934422901771 7546))), 0.04817556182698313, 4.603205300197051e-5, 2412019, 50722280559235 5699, 4112726823019557294) SymbolicRegression.PopMemberModule.PopMember{Float64}((cos(x1 / 0.63660506 56890262) - (sin(exp(x1) * 1.0363388900284802) / exp(x1))), 0.0419268037121 5973, 8.568762695441023e-5, 1359344, 682475129147039269, 320765785728912140 4) SymbolicRegression.PopMemberModule.PopMember{Float64}((cos(x1 / 0.63660506 56890262) - (sin(exp(x1) / cos(0.28864399612143354)) / exp(x1))), 0.0451293 8764414751, 8.636558026583333e-5, 2581722, 6623397325472061777, 38276093791 68211583) SymbolicRegression.PopMemberModule.PopMember{Float64}((cos(x1 * -1.5707472 736173678) - (sin(sin(exp(x1))) / exp(x1))), 0.03946124078956312, 0.0002782 5693509305236, 1189722, 6591081748771200099, 1673930060287288728) SymbolicRegression.PopMemberModule.PopMember{Float64}((cos(x1 * -1.5707472 736173678) - (sin(exp(x1)) / exp(x1))), 0.036415945717573416, 0.00031881998 770847704, 1123566, 4441784085260582951, 8874312346525345533) TECHNICAL NOTE: I ordered the model structures purely by mean squared error loss of the fits. Symbolic regression usually also incorporates a punishment for complexity of the model. I did not yet find a good way to incorporate this in the experimental design workflow, but this is definitely something that should be looked at.\nNow let us turn these symbolic expressions back into executable functions. Let us try it for the first suggested model structure:\n@syms x eqn = node_to_symbolic(best_models[1].tree, options,varMap=[\u0026#34;x\u0026#34;]) cos(-1.5707472736173678(x^1)) - sin(sin(exp(x) / cos(sin(0.0292415069409420 7 + 0.11489592239489567x))) / exp(x)) using SymbolicUtils.Code func = Func([x],[],eqn) expr = toexpr(func) _f = build_function(eqn,x) :(function (x,) #= C:\\Users\\arno\\.julia\\packages\\SymbolicUtils\\qulQp\\src\\code.jl:349 =# #= C:\\Users\\arno\\.julia\\packages\\SymbolicUtils\\qulQp\\src\\code.jl:350 =# #= C:\\Users\\arno\\.julia\\packages\\SymbolicUtils\\qulQp\\src\\code.jl:351 =# (-)((cos)((*)(-1.5707472736173678, (^)(x, 1))), (sin)((/)((sin)((/)(( exp)(x), (cos)((sin)((+)(0.02924150694094207, (*)(0.11489592239489567, x))) ))), (exp)(x)))) end) f = eval(_f) f.(X) 10-element Vector{Float64}: 0.22766738661929953 -0.08666167715710274 0.5377339408803581 -0.018287438097402808 -0.7453936527293958 -1.069802392904377 0.32276595996282476 -0.5786714569337166 -0.7262625548623343 0.09948952933242539 Now we do it for all the others and plot them:\nplot(0.0:0.1:10.0,y.(0.0:0.1:10.0),lw=5,label=\u0026#34;true model\u0026#34;,ls=:dash); model_structures = Function[] for i = 1:n_best eqn = node_to_symbolic(best_models[i].tree, options,varMap=[\u0026#34;x\u0026#34;]) fi = eval(build_function(eqn,x)) x_plot = Float64[] y_plot = Float64[] for x_try in 0.0:0.1:10.0 try y_try = fi(x_try) append!(x_plot,x_try) append!(y_plot,y_try) catch end end plot!(x_plot, y_plot,label=\u0026#34;model $i\u0026#34;); push!(model_structures,fi) end scatter!(X,Y,ms=5,label=\u0026#34;data\u0026#34;,ls=:dash); plot!(xlabel=\u0026#34;x\u0026#34;,ylabel=\u0026#34;y\u0026#34;, ylims=(-1.2,1.6)); plot!(tickfontsize=12, guidefontsize=14, legendfontsize=8, grid=false, dpi=600) We see that none of the suggested model structures approximate the true model well in the area between \\(0\\) and \\(2.5\\), while between \\(2.5\\)and \\(10\\) the models agree. In this case it is thus probably a good idea to gather more data for small \\(x\\). Can we formalize this in mathematical terms? We will do this by creating a variant of T-optimal designs. T-optimal designs are model discrimination designs, where design points are sought which maximize the distance between a model thought to be correct (T for true) and some other plausible alternative model structures. Though perhaps it is better to think of the \u0026ldquo;true\u0026rdquo; model as a null hypothesis model. Design points are chosen such that the alternative models predict different values than the \u0026ldquo;true\u0026rdquo; model at these points. If the \u0026ldquo;true\u0026rdquo; model is then not correct after all, it should be easily discernible from the data.\nIn our situation, we do not have a model structure which can serve as the \u0026ldquo;true\u0026rdquo; model. We will instead work with all pairwise distances between the plausible model structures suggested by symbolic regression. Collecting measurements where the model structures differ greatly in predictions, will cause atleast some of the model structures to become unlikely, causing new model structures to enter the top \\(10\\). We call this S-optimal, with S for Symbolics. $$N = \\text{number of measurements}$$ $$M = \\text{number of models}$$ $$f_i = \\text{ith model structure}$$ $$x_k = \\text{kth design point}$$\n$$\\max_x \\frac{2}{M(M-1)}\\sum_{i=1}^{N}\\sum_{j=i+1}^{N} \\max_{k=1 \\text{ to } M}\\set{(f_i(x_k) - f_j(x_k))^2}$$ TECHNICAL NOTE: The average over the pairwise model comparisons could be replaced with the minimum. This would lead to a max-min-max strategy instead of a max-expected-max strategy. In my experiments this did not work well when two of the suggested model structures are very similar or identical. This often occurs because of terms like \\(sin(x-x)\\) being present in symbolic regression. Punishing for complexity might remedy this.\nNow let us apply this criterion to gather $3$ new measurements:\nfunction S_criterion(x,model_structures) n_structures = length(model_structures) n_obs = length(x) if length(model_structures) == 1 # sometimes only a single model structure comes out of the equation search return 0.0 end y = zeros(n_obs,n_structures) for i in 1:n_structures y[:,i] .= model_structures[i].(x) end squared_differences = Float64[] for i in 1:n_structures for j in i+1:n_structures push!(squared_differences, maximum([k for k in (y[:,i] .- y[:,j]).^2])) end end -mean(squared_differences) # minus sign to minimize instead of maximize end function S_objective(x_new,(x_old,model_structures)) S_criterion([x_old;x_new],model_structures) end n_batch = 3 X_new_ini = rand(design_region,n_batch) S_objective(X_new_ini,(X,model_structures)) -0.015370296718503698 TECHNICAL NOTE: Can this be reformulated as a differentiable optimization problem, using slack variables?\nlb = fill(minimum(design_region),n_batch) ub = fill(maximum(design_region),n_batch) prob = OptimizationProblem(S_objective,X_new_ini,(X,model_structures),lb = lb, ub = ub) X_new = solve(prob,BBO_adaptive_de_rand_1_bin_radiuslimited(),maxtime=10.0) u: 3-element Vector{Float64}: 1.867790602985872e-18 0.22833800197426193 3.301026120902155 We see that \\(2\\) new observations are indeed both smaller than \\(2.5\\). The last one is used to discriminate between two models that are almost indistinguishable with the naked eye. Let us plot this:\nY_new = y.(X_new) plot(0.0:0.1:10.0,y.(0.0:0.1:10.0),lw=5,label=\u0026#34;true model\u0026#34;,ls=:dash); for i = 1:n_best x_plot = Float64[] y_plot = Float64[] for x_try in 0.0:0.01:10.0 try y_try = model_structures[i](x_try) append!(x_plot,x_try) append!(y_plot,y_try) catch end end plot!(x_plot, y_plot,label=\u0026#34;model $i\u0026#34;); end scatter!(X,Y,ms=5,label=\u0026#34;data old\u0026#34;); scatter!(X_new,Y_new,ms=5,label=\u0026#34;data new\u0026#34;); plot!(xlabel=\u0026#34;x\u0026#34;,ylabel=\u0026#34;y\u0026#34;, ylim=(-1.2,1.8)); plot!(tickfontsize=12, guidefontsize=14, legendfontsize=8, grid=false, dpi=600) Now, we run symbolic regression on our combined dataset:\nX = [X;X_new] Y = [Y;Y_new] hall_of_fame = EquationSearch(X\u0026#39;, Y, options=options, niterations=100, runtests=false, parallelism=:serial) n_best = min(length(hall_of_fame.members),n_best_max) best_models = sort(hall_of_fame.members,by=member-\u0026gt;member.loss)[1:n_best] plot(0.0:0.01:10.0,y.(0.0:0.01:10.0),lw=5,label=\u0026#34;true model\u0026#34;,ls=:dash); model_structures = Function[] for i = 1:n_best eqn = node_to_symbolic(best_models[i].tree, options,varMap=[\u0026#34;x\u0026#34;]) println(eqn) fi = eval(build_function(eqn,x)) x_plot = Float64[] y_plot = Float64[] for x_try in 0.0:0.01:10.0 try y_try = fi(x_try) append!(x_plot,x_try) append!(y_plot,y_try) catch end end plot!(x_plot, y_plot,label=\u0026#34;model $i\u0026#34;); push!(model_structures,fi) end scatter!(X,Y,ms=5,label=\u0026#34;data\u0026#34;); plot!(xlabel=\u0026#34;x\u0026#34;,ylabel=\u0026#34;y\u0026#34;, ylims=(-1.2,1.8)); plot!(tickfontsize=12, guidefontsize=14, legendfontsize=8, grid=false, dpi=600) Started! cos(1.5707963267136822(x^1)) - (sin(-6.283185306231179(x^1)) / exp(x)) cos(1.5707963267136822(x^1)) - (sin(-6.283185306231179(x^1)) / exp(x)) cos(1.5707963267136822(x^1)) - (sin((x^1)*((-5.283185306231179 - cos(x - x) )^1)) / exp(x)) cos(1.5707963267136822(x^1)) - (sin((x^1)*((-5.283185306231179 - exp(1.5707 963267136822((x - x)^1)))^1)) / exp(x)) cos(1.5707963267136822(x^1)) - (sin((-5.283185306231179(x^1)) - x) / exp(x) ) cos(1.5707963267136822(x^1)) - (sin(((-5.283185306231179 / x)*(x^2)) - x) / exp(x)) cos(1.5707963267136822(x^1)) - (sin(((sin(x) - 5.283185306231179x) - x) - s in(x)) / exp(x)) cos(1.5707963265959193(x^1)) - (sin(x / -0.15915494382513268) / exp(x)) cos(1.5707768686144095(x^1)) - (sin(x / -0.1589621029216852) / exp(x)) cos(1.571732202757438(x^1)) - sin(0.2460674037875204 / (x*x)) Et voilà, we found the correct model structure, with only 3 new observations!\nTECHNICAL NOTE: In fact we found it multiple times, with expressions like \\(sin(x-x)\\). Again, punishing for needless complexity would be of added value here.\n","date":"1 January 2023","permalink":"/websiteplayground/posts/soptimal/","section":"","summary":"\u003cp\u003e\n\nMost experimental design focusses on parameter precision,\nwhere the model structure is assumed known and fixed.\nBut arguably finding the correct model structure\nis the part of the modelling process that takes the most effort.\nIn this blog we will look at automating this process using symbolic regression,\nand to do this with gathering too much data.\u003c/p\u003e","title":"Design for model discrimination using symbolic regression"},{"content":" We continue from part 1 with a more rigorous version of the derivation of adjoint sensitivity analysis for continuous time systems, $$\\begin{align*} u(0) \u0026amp;= f_0(p)\\\\ u(t) \u0026amp;= u(0) + \\int_0^{t} f(u(q),p,q)dq\\\\ c(t) \u0026amp;= g(u(t),p,t)\\\\ G(c) \u0026amp;= \\int_0^{t_e } c(s)ds, \\end{align*}$$ \\(u(t)\\) is the dynamic state, which evolution in time is described by the function \\(f\\). \\(c(t)\\) is the cost at time \\(t\\) described by the function \\(g\\) and \\(G\\) is the total accumulated cost. Both \\(g\\) and \\(f\\) are dependent on the parameters \\(p\\) and the time \\(t\\). We want to calculate the effect \\(p\\) has on \\(G\\) using backpropagation.\nLet us assume that we have already pulled back from time \\(t_e\\) to time \\(t\\). We reparametrize \\(G\\) in terms of \\(p\\), \\(u(t)\\) and \\(c_{[0,t]}\\), which is the cost function restricted to the interval \\([0,t]\\), $$\\begin{align*} G(c_{[0,t]},u(t),p) = \\int_0^t c(s)ds + \u0026amp;\\int_t^{t_e} g(u(s),p,s)ds\\\\ \u0026amp;\\text{with}\\qquad u(s) = u(t) + \\int_t^s f(u(q),p,q)dq. \\end{align*}$$ If we assume that the partial derivative of \\(G(c_{[0,t]},u(t),p)\\) with regards to \\(u(t)\\) is equal to \\(\\lambda(t)\\),\n$$\\frac{\\partial G(c_{[0,t]},u(t),p)}{\\partial u(t)} = \\frac{\\partial \\int_t^{t_e} g(u(s),p,s)ds}{\\partial u(t)} = \\lambda(t),$$\nthen we can calculate the same partial derivative at a slightly further pulled back timepoint of \\(t-\\Delta t\\).\n$$\\begin{align*} \\frac{\\partial G(c_{[0,t-\\Delta t]},u(t-\\Delta t),p)}{\\partial u(t-\\Delta t)} \u0026amp;=\\frac{\\partial \\left( \\int_0^{t-\\Delta t} c(s) ds + \\int_{t-\\Delta t}^{t_e} g(u(s),p,s)ds\\right)}{\\partial u(t-\\Delta t)} \\\\ \u0026amp;=\\frac{\\partial \\left( \\int_{t-\\Delta t}^tg(u(s),p,s)ds + \\int_t^{t_e} g(u(s),p,s)ds\\right)}{\\partial u(t-\\Delta t)} \\\\ \u0026amp;=\\frac{\\partial \\int_{t-\\Delta t}^tg(u(s),p,s)ds}{\\partial u(t-\\Delta t)} + \\frac{\\partial \\int_t^{t_e} g(u(s),p,s)ds}{\\partial u(t)}\\frac{\\partial u(t)}{\\partial u(t-\\Delta t)} \\\\ \u0026amp;=\\frac{\\partial \\int_{t-\\Delta t}^tg(u(s),p,s)ds}{\\partial u(t-\\Delta t)} + \\lambda(t)\\frac{\\partial u(t)}{\\partial u(t-\\Delta t)} \\\\ \\end{align*}$$\nUsing the mean value theorem, we can write the second term as,\n$$\\begin{align*} \\frac{\\partial u(t)}{\\partial u(t-\\Delta t)} \u0026amp;= \\frac{\\partial \\left( u(t-\\Delta t) + \\int_{t-\\Delta t}^t f(u(q),p,q)dq\\right) }{\\partial u(t-\\Delta t)}\\\\ \u0026amp; = 1 + \\frac{\\partial \\int_{t-\\Delta t}^tf(u(q),p,q)dq}{\\partial u(t-\\Delta t)}\\\\ \u0026amp; = 1 + \\frac{\\partial f(u(t-\\Delta t_f),p,t-\\Delta t_f)}{\\partial u(t-\\Delta t)}\\Delta t \\qquad \\Delta t_f \\in [0,\\Delta t]\\\\ \u0026amp; = 1 + \\frac{\\partial f(u(t-\\Delta t_f),p,t-\\Delta t_f)}{\\partial u(t-\\Delta t_f)}\\frac{\\partial u(t-\\Delta t_f)}{\\partial u(t-\\Delta t)}\\Delta t\\\\ \u0026amp; = 1 + \\frac{\\partial f(u(t-\\Delta t_f),p,t-\\Delta t_f)}{\\partial u(t-\\Delta t_f)}\\Delta t + \\\\ \u0026amp; \\qquad \\frac{\\partial f(u(t-\\Delta t_{f_2}),p,t-\\Delta t_{f_2})}{\\partial u(t-\\Delta t)}\\Delta t(\\Delta t - \\Delta t_f) \\qquad \\Delta t_{f_2} \\in [\\Delta t_f,\\Delta t], \\end{align*}$$\nand the second term as,\n$$\\begin{align*} \\frac{\\partial \\int_{t-\\Delta t}^tg(u(s),p,s)ds}{\\partial u(t-\\Delta t)} \u0026amp;= \\frac{\\partial g(u(t-\\Delta t_g),p,t-\\Delta t_g)}{\\partial u(t-\\Delta t)}\\Delta t \\qquad \\Delta t_g \\in [0,\\Delta t] \\\\ \u0026amp;= \\frac{\\partial g(u(t-\\Delta t_g),p,t-\\Delta t_g)}{\\partial u(t-\\Delta t_g)}\\frac{\\partial u(t-\\Delta t_g)}{\\partial u(t-\\Delta t)}\\Delta t\\\\ \u0026amp;= \\frac{\\partial g(u(t-\\Delta t_g),p,t-\\Delta t_g)}{\\partial u(t-\\Delta t_g)}\\Delta t + \\\\ \u0026amp; \\qquad \\frac{\\partial f(u(t-\\Delta t_{g_2}),p,t-\\Delta t_{g_2})}{\\partial u(t-\\Delta t)}\\Delta t(\\Delta t - \\Delta t_g) \\qquad \\Delta t_{g_2} \\in [\\Delta t_g,\\Delta t]. \\end{align*}$$\nWe can obtain a differential equation for \\(\\lambda\\) by taking the limit,\n$$\\begin{align*} \\frac{d\\lambda}{dt} \u0026amp; = \\lim_{\\Delta t \\to 0} \\frac{\\frac{\\partial G(c_{[0,t]},u(t),p)}{\\partial u(t)} -\\frac{\\partial G(c_{[0,t-\\Delta t]},u(t-\\Delta t),p)}{\\partial u(t-\\Delta t)}}{\\Delta t} \\\\ \u0026amp; = \\lim_{\\Delta t \\to 0} \\left( -\\frac{\\partial g(u(t-\\Delta t_g),p,t-\\Delta t_g)}{\\partial u(t-\\Delta t_g)} - \\lambda(t)\\frac{\\partial f(u(t-\\Delta t_f),p,t-\\Delta t_f)}{\\partial u(t-\\Delta t_f)} + \\right. \\\\ \u0026amp; \\qquad \\left. \\vphantom{\\frac{\\partial}{\\partial}}\\ldots (\\Delta t - \\Delta t_{g_2}) + \\ldots (\\Delta t - \\Delta t_{f_2}) \\right)\\\\ \u0026amp; = -\\frac{\\partial g(u(t),p,t)}{\\partial u(t)} - \\lambda(t)\\frac{\\partial f(u(t),p,t)}{\\partial u(t)} \\end{align*}$$ This differential equation is the same as the one found in part 1. It is a good exercise to try the same technique on \\(\\frac{\\partial G(c_{[0,t]},u(t),p)}{\\partial p}\\).\n","date":"30 April 2022","permalink":"/websiteplayground/posts/adjoint-sensitivity2/","section":"","summary":"\u003cp\u003e\n\nWe continue from \u003ca href=\"https://arnostrouwen.github.io/websiteplayground/posts/adjoint-sensitivity/\"\u003epart 1\u003c/a\u003e with a more rigorous version of the derivation of adjoint sensitivity analysis for continuous time systems,\n$$\\begin{align*}\nu(0) \u0026amp;= f_0(p)\\\\\nu(t) \u0026amp;= u(0) + \\int_0^{t} f(u(q),p,q)dq\\\\\nc(t) \u0026amp;= g(u(t),p,t)\\\\\nG(c) \u0026amp;= \\int_0^{t_e } c(s)ds,\n\\end{align*}$$\n\\(u(t)\\) is the dynamic state, which evolution in time is described by the function \\(f\\).\n\\(c(t)\\) is the cost at time \\(t\\) described by the function \\(g\\) and \\(G\\) is the total accumulated cost.\nBoth \\(g\\) and \\(f\\) are dependent on the parameters \\(p\\) and the time \\(t\\). We want to calculate the effect \\(p\\) has on \\(G\\) using backpropagation.\u003c/p\u003e","title":"Notes on adjoint sensitivity analysis of dynamic systems part 2"},{"content":" Gradients are useful for efficient parameter estimation and optimal control of dynamic systems. Calculating these gradients requires sensitivity analysis. Sensitivity analysis for dynamic systems comes in two flavors, forward mode and adjoint (reverse). For systems with a large number of parameters adjoint sensitivity analysis is often more efficient [1]. I find that the traditional way of deriving adjoints for ordinary differential equations, such as [3], leaves me with little intuition what these equations represent. The goal of this blog post is to gain some intuition about these equations by deriving the adjoint equations in a different way.\nA prerequisite for understanding this post is being comfortable with the concept of backpropagation used in machine learning. If you are not familiar with this, I recommend you first read [2], until you are comfortable with the backpropagation example of logistic regression.\nTo better understand adjoint sensitivity analysis for continuous time systems, we first start from the simpler case of discrete-time dynamic systems. We want to the backpropagate the influence the parameters \\(p\\) have on the total cost \\(C\\) in the following computation,\n$$\\begin{align*} u_0 \u0026amp;= f_0(p)\\\\ u_1 \u0026amp;= f_1(u_0,p)\\\\ c_1 \u0026amp;= g_1(u_1,p)\\\\ u_2 \u0026amp;= f_2(u_1,p)\\\\ c_2 \u0026amp;= g_2(u_2,p)\\\\ C \u0026amp;= G(c_1, c_2) = c_1+c_2. \\end{align*}$$\nIn these equations \\(u_0\\) is the initial state of the dynamic system, which is a function of the parameters. The transition from the initial state to the next state \\(u_1\\) is described by the function \\(f_1\\), which is a function of the initial state and the parameters. Similarly, there is another transition \\(f_2\\) to \\(u_2\\). For simplicity, we only consider a dynamic system with two steps. For each of the two states \\(u_1\\) and \\(u_2\\) there is an associated cost function \\(c_1\\) and \\(c_2\\), these costs can also be function of the parameters. The total cost \\(C\\) is the sum of the two individual costs. Backpropagation will eventually lead to the gradient of \\(G\\) towards \\(p\\).\nNOTE\nIn the following equations we will write the function \\(G\\) with different inputs. \\(G\\) is the only function for which this is done, all other functions, such as \\(f_1\\), will only be considered as functions of the inputs they are written as in the above system.\nThe gradient of \\(G\\) towards \\(c_1\\) and \\(c_2\\) is not difficult to calculate,\n$$\\nabla G(c_1, c_2) = \\nabla(c_1+c_2) = [1,1]^T.$$\nNow let us take a step back and substitute \\(c_2\\) with \\(u_2\\) and \\(p\\),\n$$ \\nabla G(c_1, u_2, p) = \\nabla(c_1+g_2(u_2,p)) = \\left[1, \\frac{\\partial g_2}{\\partial u_2}, \\frac{\\partial g_2}{\\partial p} \\right]^T. $$\nCall the second to last element of this vector,\n$$\\lambda_2 = \\frac{\\partial g_2}{\\partial u_2},$$\nand call the last element of this vector,\n$$\\phi_2 = \\frac{\\partial g_2}{\\partial p}.$$\nNow we pull back some more and substitute \\(c_1\\) with \\(u_1\\) and \\(p\\), and also substitute \\(u_2\\) with \\(u_1\\) and \\(p\\),\n$$\\begin{align*} \\nabla G(u_1, p) \u0026amp;= \\nabla(g_1(u_1,p)+g_2(f_2(u_1,p),p)) \\\\ \u0026amp;= \\left[ \\frac{\\partial g_1}{\\partial u_1} + \\frac{\\partial g_2}{\\partial u_2}\\frac{\\partial f_2}{\\partial u_1}, \\frac{\\partial g_1}{\\partial p} + \\frac{\\partial g_2}{\\partial p} + \\frac{\\partial g_2}{\\partial u_2}\\frac{\\partial f_2}{\\partial p} \\right]^T. \\end{align*}$$\nNow note that the second to last element of this vector can be written as,\n$$\\lambda_1 = \\frac{\\partial g_1}{\\partial u_1} + \\lambda_2 \\frac{\\partial f_2}{\\partial u_1},$$\nand the last element as,\n$$\\phi_1 = \\lambda_2 \\frac{\\partial f_2}{\\partial p} + \\frac{\\partial g_1}{\\partial p} + \\phi_2.$$\nSubstituting \\(u_1\\) with \\(u_0\\) and \\(p\\) works the same,\n$$\\begin{align*} \\nabla G(u_0, p) \u0026amp;= \\nabla(g_1(f_1(u_0,p),p)+g_2(f_2(f_1(u_0,p),p),p) \\\\ \u0026amp;=\\left[ \\frac{\\partial g_1}{\\partial u_1}\\frac{\\partial f_1}{\\partial u_0}+ \\frac{\\partial g_2}{\\partial u_2}\\frac{\\partial f_2}{\\partial u_1}\\frac{\\partial f_1}{\\partial u_0}, \\frac{\\partial g_1}{\\partial p} + \\frac{\\partial g_1}{\\partial u_1}\\frac{\\partial f_1}{\\partial p} + \\frac{\\partial g_2}{\\partial p} + \\frac{\\partial g_2}{\\partial u_2}\\frac{\\partial f_2}{\\partial p} + \\frac{\\partial g_2}{\\partial u_2}\\frac{\\partial f_2}{\\partial u_1}\\frac{\\partial f_1}{\\partial p} \\right]^T, \\end{align*}$$\n$$\\lambda_0 = \\lambda_1 \\frac{\\partial f_1}{\\partial u_0},$$\n$$\\phi_0 = \\lambda_1 \\frac{\\partial f_1}{\\partial p} + \\phi_1.$$\nSubstituing \\(u_0\\) with \\(p\\) gives the desired gradient,\n$$\\begin{align*} \\nabla G(p) \u0026amp;= \\nabla(g_1(f_1(f_0(p),p),p)+g_2(f_2(f_1(f_0(p),p),p),p)\\\\ \u0026amp;=\\left[ \\frac{\\partial g_1}{\\partial p} + \\frac{\\partial g_1}{\\partial u_1}\\frac{\\partial f_1}{\\partial p} + \\frac{\\partial g_1}{\\partial u_1}\\frac{\\partial f_1}{\\partial u_0}\\frac{\\partial f_0}{\\partial u_p} + \\frac{\\partial g_2}{\\partial p} + \\frac{\\partial g_2}{\\partial u_2}\\frac{\\partial f_2}{\\partial p} + \\frac{\\partial g_2}{\\partial u_2}\\frac{\\partial f_2}{\\partial u_1}\\frac{\\partial f_1}{\\partial p} + \\frac{\\partial g_2}{\\partial u_2}\\frac{\\partial f_2}{\\partial u_1}\\frac{\\partial f_1}{\\partial u_0}\\frac{\\partial f_0}{\\partial u_p} \\right]^T\\\\ \u0026amp;=\\left[ \\lambda_0 \\frac{\\partial f_0}{\\partial p} + \\phi_0 \\right]^T. \\end{align*}$$\nYou should check that, for a high dimensional \\(p\\), this recursion based on \\(\\lambda\\) and \\(\\phi\\), involves less costly matrix multiplications than the forward mode sensitivity analysis:\n$$\\begin{align*} \\frac{\\partial u_0}{\\partial p} \u0026amp;= \\frac{\\partial f_0}{\\partial p}\\\\ \\frac{\\partial u_1}{\\partial p} \u0026amp;= \\frac{\\partial f_1}{\\partial u_0}\\frac{\\partial u_0}{\\partial p} + \\frac{\\partial f_1}{\\partial p}\\\\ \\frac{\\partial c_1}{\\partial p} \u0026amp;= \\frac{\\partial g_1}{\\partial u_1}\\frac{\\partial u_1}{\\partial p} + \\frac{\\partial g_1}{\\partial p}\\\\ \\frac{\\partial u_2}{\\partial p} \u0026amp;= \\frac{\\partial f_2}{\\partial u_1}\\frac{\\partial u_1}{\\partial p} + \\frac{\\partial f_2}{\\partial p}\\\\ \\frac{\\partial c_2}{\\partial p} \u0026amp;= \\frac{\\partial g_2}{\\partial u_2}\\frac{\\partial u_2}{\\partial p} + \\frac{\\partial g_2}{\\partial p}\\\\ \\frac{\\partial G}{\\partial p} \u0026amp;= \\frac{\\partial c_1}{\\partial p} + \\frac{\\partial c_2}{\\partial p}. \\end{align*}$$\nNow we know how to calculate the pullback of a difference equation. Can we extend this intuition to continuous time systems? If we assume that \\(f_k\\) comes from a forward euler discretization of a function \\(f_c\\),\n$$f_{k+1}(u_k,p) = u_k + \\Delta t f^c(u_k,p),$$\nand we assume that \\(g_k\\) is the accumulation of a continuous cost function \\(g^c\\), which can be considered constant in a short time-window \\(\\Delta t\\),\n$$g_k(u_k,p) = \\Delta t g^c(u_k,p),$$\nthen we can calculate the recursion for \\(\\lambda\\) as,\n$$ \\lambda_{k} = \\frac{\\partial g_k}{\\partial u_k} + \\lambda_{k+1} \\frac{\\partial f_{k+1}}{\\partial u_k} = \\Delta t\\frac{\\partial g^c}{\\partial u_k} + \\lambda_{k+1} \\left(1+\\Delta t\\frac{\\partial f^c}{\\partial u_k}\\right), $$\nwhich is the backwards euler solve of the differential equation,\n$$\\begin{align*} \\frac{\\lambda_{k+1} - \\lambda_{k}}{\\Delta t} \u0026amp;= -\\frac{\\partial g^c}{\\partial u_k}- \\lambda_{k+1} \\frac{\\partial f^c}{\\partial u_k},\\\\ \\frac{d\\lambda}{dt} \u0026amp;= -\\frac{\\partial g^c}{\\partial u} - \\lambda \\frac{\\partial f^c}{\\partial u}. \\end{align*}$$\nSimilarly we can calculate the recursion for \\(\\phi\\) as:\n$$\\begin{align*} \\phi_k \u0026amp;= \\lambda_{k+1} \\frac{\\partial f_{k+1}}{\\partial p} + \\frac{\\partial g_k}{\\partial p} + \\phi_{k+1},\\\\ \\frac{\\phi_{k+1}-\\phi_k }{\\Delta t} \u0026amp;= -\\lambda_{k+1} \\frac{\\partial f^c}{\\partial p} - \\frac{\\partial g^c}{\\partial p},\\\\ \\frac{d\\phi}{dt} \u0026amp;= -\\lambda \\frac{\\partial f^c}{\\partial p} - \\frac{\\partial g^c}{\\partial p}. \\end{align*}$$\nThese are the same equations you find in the documentation of DifferentialEquations.jl [4]. This, however, only gives us an intuition behind the equations for continuous time systems. In part 2 we will see if a more rigorous version of this argument can be made for continuous time systems.\nReferences Y. Ma, V. Dixit, M. J. Innes, X. Guo and C. Rackauckas, \u0026ldquo;A Comparison of Automatic Differentiation and Continuous Sensitivity Analysis for Derivatives of Differential Equation Solutions,\u0026rdquo; 2021 IEEE High Performance Extreme Computing Conference (HPEC), 2021, pp. 1-9. Lecture 10 of the Parallel Computing and Scientific Machine Learning course Lecture 11 of the Parallel Computing and Scientific Machine Learning course SciML sensitivity analysis documentation ","date":"31 January 2022","permalink":"/websiteplayground/posts/adjoint-sensitivity/","section":"","summary":"\u003cp\u003e\n\nGradients are useful for efficient parameter estimation and optimal control of dynamic systems.\nCalculating these gradients requires sensitivity analysis.\nSensitivity analysis for dynamic systems comes in two flavors, forward mode and adjoint (reverse).\nFor systems with a large number of parameters adjoint sensitivity analysis is often more efficient\n\u003ca href=\"https://ieeexplore.ieee.org/abstract/document/9622796\" target=\"_blank\" rel=\"noreferrer\"\u003e[1]\u003c/a\u003e.\nI find that the traditional way of deriving adjoints for ordinary differential equations, such as\n\u003ca href=\"https://book.sciml.ai/notes/11-Differentiable_Programming_and_Neural_Differential_Equations/\" target=\"_blank\" rel=\"noreferrer\"\u003e[3]\u003c/a\u003e,\nleaves me with little intuition what these equations represent.\nThe goal of this blog post is to gain some intuition about these equations by deriving the adjoint equations in a different way.\u003c/p\u003e","title":"Notes on adjoint sensitivity analysis of dynamic systems part 1"},{"content":" Optimal experimental design is an area of statistics focused on constructing informative experiments. In this tutorial we introduce the necessary tools to construct such informative experiments for dynamic systems using only 100 lines of Julia code. We will work with a well-mixed fed-batch bioreactor as an example system. We have quite a bit of domain knowledge how to model the behavior of such a reactor. The reactor has three dynamic states: the substrate concentration \\(C_s\\), the biomass concentration \\(C_x\\) and the volume of the reactor \\(V\\). The evolution in time of these states is governed by the following differential equations:\n$$\\begin{align*} \\frac{dC_s}{dt} \u0026amp;= -\\sigma C_x + \\frac{Q_{in}(t)}{V}(C_{S,in} - C_s)\\\\ \\frac{dC_x}{dt} \u0026amp;= \\mu C_x - \\frac{Q_{in}(t)}{V}C_x\\\\ \\frac{dV}{dt} \u0026amp;= Q_{in}(t), \\end{align*}$$ where,\n$$\\begin{align*} \\mu \u0026amp;= \\frac{\\mu_{max}C_s}{K_s + C_s}\\\\ \\sigma \u0026amp;= \\frac{\\mu}{y_{x,s}} + m. \\end{align*}$$\nNot all parameters in these equations are exactly known. We are unsure of the value of the maximal growth rate \\(\\mu_{max}\\), and the half saturation constant \\(K_s\\). We want to construct an experiment to learn about these parameters. To reach this goal we can control the volume of the reactor by the volumetric flow rate \\(Q_{in}(t)\\). And we will measure the two states \\(C_s\\) and \\(C_x\\). The other parameters in the equation, namely the substrate feed concentration \\(C_{S,in}\\), the maintenance factor \\(m\\) and yield \\(y_{x,s}\\), are considered to be exactly known. All of the numerical values we will use are taken from [1].\nThe packages that we will use:\nusing OrdinaryDiffEq using DiffEqFlux using ForwardDiff using Distributions using Quadrature using Optim using LinearAlgebra using Plots using Random Defining the system First, we define the dynamics of the fed-batch reactor.\nfunction dynamics!(du,u,p,t) C_s, C_x, V = u μ_max, K_s = @view p[1:n_θ] control_par = @view p[n_θ+1:end] Q_in = control_network(t, control_par)[1] C_s_in, y_x_s, m = 50.0, 0.777, 0.0 μ = μ_max*C_s/(K_s + C_s) σ = μ/y_x_s + m du[1] = -σ*C_x + Q_in/V*(C_s_in - C_s) du[2] = μ*C_x - Q_in/V*C_x du[3] = Q_in return nothing end Finding the optimal controls is an infinite dimensional optimization problem. To reduce the complexity of this problem to a non-linear optimization one, we use a parametrized control function. We call this parametrization \\(x\\), and in this case we use a neural network with three hidden layers, each with five neurons. Time \\(t\\) is the only input to this neural network and the flow rate \\(Q_{in}\\) is the only output. Note that the last activation function constrains the control input between 0 and 10. You can fine-tune the amount of hidden layers and neurons as well as the different activation functions to achieve even better experiments than presented in this tutorial.\nRandom.seed!(45415) const control_network = FastChain(FastDense(1, 5,gelu), FastDense(5, 5,swish), FastDense(5, 5,relu), FastDense(5, 1,z-\u0026gt;10.0 .*sigmoid(z))) const x_ini = randn(length(initial_params(control_network))) const n_x = length(x_ini) Next, we define the true value of the two uncertain parameters \\(\\theta\\). We will use the true values for a simulation study to test the performance of our experiment. Both the uncertain parameters and the control parameters will have to be passed together as the \\(p\\) argument of dynamics!.\nconst θ_t = [0.421, 0.439] const n_θ = length(θ_t ) const p = vcat(θ_t,x_ini) Our experiment will last 15 hours. The initial conditions of the dynamics, \\(u_0\\), are fixed.\nconst tspan = (0.0, 15.0) const u_0 = [3.0, 0.25, 7.0] const n_u = length(u_0) We continue by simulating the true system.\nprob = ODEProblem(dynamics!,u_0,tspan,p) sol = solve(prob,Tsit5(),reltol=1e-5,abstol=1e-5) plot(sol;label=[\u0026#34;Cₛ(g/L)\u0026#34; \u0026#34;Cₓ(g/L)\u0026#34; \u0026#34;V(L)\u0026#34;],xlabel=\u0026#34;t(h)\u0026#34;,lw=3) plot!(tickfontsize=12,guidefontsize=14,legendfontsize=14,grid=false, dpi=600) Some optimal experimental design theory Generally, we do not measure all the dynamic states continuously, but instead we take measurements \\(y_k\\), which are some function of the states \\(u\\) at discrete time points,\n$$\\begin{align*} \\frac{du}{dt} \u0026amp;= f(u,\\theta,x,t)\\\\ y_k(\\theta,x) \u0026amp;= h(u(\\theta,x,t_k)). \\end{align*}$$\nIn our case we measure the substrate and biomass concentration every hour. These measurements should inform us about the true value of the uncertain parameters. Often these measurements are noisy, with covariance \\(\\Sigma\\).\nconst tmeasurement = 0.0:1.0:15.0 const Σ = [0.001 0.0; 0.0 0.000625] The Fisher information matrix (FIM) \\(F\\) is a popular way to quantify this information content of an experiment,\n$$F(\\theta,x) = \\sum_k \\frac{\\partial y_k\u0026rsquo;}{\\partial\\theta}\\Sigma^{-1} \\frac{\\partial y_k}{\\partial\\theta}.$$\nThe intuition behind this formula is that in a good experiment the measurements should be sensitive towards the value of the uncertain model parameters. If the experiment is such that the measurements are similar no matter what the value of the true parameter is, then it will be hard to precisely determine that parameter value. These sensitivities of the measurements towards the uncertain parameters can be further expanded,\n$$\\frac{\\partial y_k(\\theta,x)}{\\partial\\theta} = \\frac{\\partial h}{\\partial u} \\frac{\\partial u(\\theta,x,t_k)}{\\partial\\theta}.$$\nSince we only measure the first two states, the first factor, \\(\\frac{\\partial h}{\\partial u}\\), is equal to the matrix [1 0; 0 1; 0 0]. The second factor can be calculated from the forward sensitivity transform of the differential equation system,\n$$\\begin{align*} \\frac{d}{dt}\\frac{\\partial u(\\theta,x,t)}{\\partial\\theta} \u0026amp;= \\frac{\\partial}{\\partial\\theta}\\frac{du(\\theta,x,t)}{dt} = \\frac{\\partial f(u,\\theta,x,t)}{\\partial u}\\frac{\\partial u}{\\partial \\theta} + \\frac{\\partial f(u,\\theta,x,t)}{\\partial \\theta}\\\\ \\frac{\\partial u(\\theta,x,t=0)}{\\partial \\theta} \u0026amp;= 0. \\end{align*}$$\nIn Julia this can be done using forward mode automatic differentiation. We want the Fisher information matrix to be as large as possible, but what constitutes a large matrix? The inverse of the FIM is related to confidence ellipsoids and we want these ellipsoids to be as small as possible volume wise, which turns out to be equivalent to maximizing the determinant of the FIM. In the experimental design literature, these are called D-optimal experiments. In Julia this can be done in the following way:\nfunction solve_wrap(θ,x) p = [θ;x] prob = ODEProblem(dynamics!,u_0,tspan,p) sol = solve(prob,Tsit5(),saveat=tmeasurement,reltol=1e-5,abstol=1e-5) u = convert(Array,sol) end function D_criterion(θ,x) FIM = zeros(eltype(x),n_θ,n_θ) jac = ForwardDiff.jacobian(θ-\u0026gt;solve_wrap(θ,x),θ) for k in 1:length(tmeasurement) du_dθ = jac[(k-1)*n_u+1:k*n_u,:] dy_θ = du_dθ[1:2,:] FIM += dy_θ\u0026#39;*inv(Σ)*dy_θ end return det(FIM) end The major issue with experimental design based on the Fisher information matrix, is the dependence of the optimal design on the true model parameter values that the experiment aims to learn about. We can robustify this by averaging the D-criterion over a distribution of possible parameter values. We specify the uncertainty on the model parameters as probability distributions provided by Distributions.jl. We use truncated normal distributions centered around \\(4.0\\) for both uncertain parameters. The expectation is calculated rather inaccurately to speed up the tutorial.\nfunction robust_D_criterion(x) θ_dist = product_distribution([truncated(Normal(0.4,0.1),0.1,0.7),truncated(Normal(0.4,0.1),0.1,0.7)]) integrand(θ,x) = D_criterion(θ,x)*pdf(θ_dist,θ) prob_quadrature = QuadratureProblem(integrand,minimum(θ_dist),maximum(θ_dist),x) sol_quadrature = solve(prob_quadrature,HCubatureJL(),reltol = 1e-2, abstol = 1e-2)[1] end Optimal experiment Finally, we get to optimizing the controls. A first order optimization technique is used. Optim.jl is capable of calculating the required gradient using automatic differentiation.\nx_opt = optimize(x-\u0026gt; -robust_D_criterion(x), x_ini, BFGS(), Optim.Options(iterations=10), autodiff = :forward).minimizer t_plot = 0.0:0.1:15 plot(t_plot,[control_network(t, x_ini)[1] for t in t_plot ],label=\u0026#34;initial experiment\u0026#34;,lw=3) plot!(t_plot,[control_network(t, x_opt)[1] for t in t_plot],label=\u0026#34;optimized experiment\u0026#34;,lw=3) plot!(xlabel=\u0026#34;t(h)\u0026#34;, ylabel=\u0026#34;Q(l/h)\u0026#34;) plot!(tickfontsize=12,guidefontsize=14,legendfontsize=14,grid=false,ylim=(-1,11), dpi=600) Now all that remains is showing the added value of the optimal experiment. We simulate many experiments according to both the design we started with, and the optimized design, using the true parameter values. We then see how precisely, we can recover the true parameters from the simulated data sets. The optimized experiment\u0026rsquo;s parameter estimates are generally closer to the true parameter values than the initial experiment we started with.\nRandom.seed!(454154) function SSE(θ,x) prob = ODEProblem(dynamics!,u_0,tspan,vcat(θ,x)) sol = solve(prob,Tsit5(),saveat=tmeasurement,reltol=1e-5) y_est = sol[1:2,:] errors = y_measure - y_est errors_scaled = sqrt(inv(Σ))*errors sum(errors_scaled.^2) end y_true = solve(ODEProblem(dynamics!,u_0,tspan,vcat(θ_t,x_ini)),Tsit5(), saveat=tmeasurement,reltol=1e-5,abstol=1e-5)[1:2,:] θ_estimates = zeros(n_θ,100) for j = 1:100 global y_measure = y_true + rand(MvNormal(Σ),length(tmeasurement)) θ_estimates[:,j] = optimize(θ-\u0026gt;SSE(θ,x_ini), θ_t).minimizer end Plots.scatter(θ_estimates[1,:],θ_estimates[2,:],label=\u0026#34;unoptimized experiment\u0026#34;,ms=5) y_true = solve(ODEProblem(dynamics!,u_0,tspan,vcat(θ_t,x_opt)),Tsit5(), saveat=tmeasurement,reltol=1e-5,abstol=0.0)[1:2,:] for j = 1:100 global y_measure = y_true + rand(MvNormal(Σ),length(tmeasurement)) θ_estimates[:,j] = optimize(θ-\u0026gt;SSE(θ,x_opt), θ_t).minimizer end Plots.scatter!(θ_estimates[1,:],θ_estimates[2,:],label=\u0026#34;optimized experiment\u0026#34;,ms=5) plot!(xlabel=\u0026#34;μₘₐₓ\u0026#34;,ylabel=\u0026#34;Kₛ\u0026#34;) plot!(tickfontsize=12,guidefontsize=14,legendfontsize=14,grid=false, dpi=600) The precisely estimated parameters can subsequently be used to obtain a better control of the bio-reactor to, for example, grow as much biomass as possible. Currently, the design optimization is implemented using forward over forward automatic differentiation. It would be more efficient to instead do this with reverse over forward automatic differentiation, but this is not yet easy to do in Julia.\nReferences Telen, Dries, et al. \u0026ldquo;Robustifying optimal experiment design for nonlinear, dynamic (bio) chemical systems.\u0026rdquo; Computers \u0026amp; chemical engineering 71 (2014): 415-425. ","date":"30 September 2021","permalink":"/websiteplayground/posts/dynamic-experimental-design/","section":"","summary":"\u003cp\u003e\n\nOptimal experimental design is an area of statistics focused on constructing informative experiments.\nIn this tutorial we introduce the necessary tools to construct such informative experiments for dynamic systems using only 100 lines of Julia code.\nWe will work with a well-mixed fed-batch bioreactor as an example system. We have quite a bit of domain knowledge how to model the behavior of such a reactor.\nThe reactor has three dynamic states: the substrate concentration \\(C_s\\), the biomass concentration \\(C_x\\) and the volume of the reactor \\(V\\).\nThe evolution in time of these states is governed by the following differential equations:\u003c/p\u003e","title":"Dynamic experimental design in 100 lines of Julia code"},{"content":"I am a statistical consultant focused on experimental design and other optimal data gathering techniques, particularly for dynamic systems.\nOften, researchers will perform experiments and only talk to a statistician afterwards. But statisticians are not only useful for data analysis. Much time and effort can be saved by carefully planning an experiment. Every measurement setup has its own unique details. I help other researchers by constructing optimal experiments, custom made for their own measurement setup, goals and budgetary constraints.\nMuch of my expertise in experimental design, I developed during my Research Foundation Flanders (FWO) PhD fellowship at the KULeuven. There, I designed experiments to precisely characterize the respiration and fermentation of fruit and vegetables, leading to better storage solutions.\nAfter graduating, I joined the manufacturing and applied statistics department of Johnson \u0026amp; Johnson to valorize the ideas developed in my PhD. I worked on designing accelerated stability studies to precisely predict the shelf life of vaccines and other drug products. Some of my other responsibilities included designing high-throughput experiments to optimize the manufacturing conditions of chemical reactions, Bayesian mixed effect modelling to determine the mechanical properties of powders, and optimally blocking experiments when full randomization is not an option.\nI then felt ready for a new challenge, starting my own consulting company, Strouwen Statistics. My first client is JuliaHub, where I work on the statistical aspects of the quantitative systems pharmacology software, PumasQSP, as well as the battery simulation software, JuliaSimBatteries. I am also responsible for the continuous integration and delivery of the documentation of the Scientific Machine Learning Project (SciML).\n","date":null,"permalink":"/websiteplayground/about/","section":"","summary":"I am a statistical consultant focused on experimental design and other optimal data gathering techniques, particularly for dynamic systems.","title":"About me"},{"content":"","date":null,"permalink":"/websiteplayground/categories/","section":"Categories","summary":"","title":"Categories"},{"content":"","date":null,"permalink":"/websiteplayground/tags/","section":"Tags","summary":"","title":"Tags"}]